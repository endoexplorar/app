{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMFUi_ID25Au",
        "outputId": "79e3ad35-e427-4272-e8a3-52af456f1456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Arquivo de sumário salvo em: /content/drive/My Drive/sumario.txt\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from statsmodels.stats.anova import AnovaRM\n",
        "from scipy.stats import ttest_rel\n",
        "from google.colab import drive\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# URL da planilha do Google Sheets\n",
        "sheet_id = '1p2-JXILLC0urC0oiTOHjbO1579CtXW2RfUIAK6R_z4c'\n",
        "sheet_name = 'Sheet1'  # Substitua pelo nome da aba, se necessário\n",
        "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
        "\n",
        "# Ler os dados da planilha usando pandas\n",
        "try:\n",
        "    df = pd.read_csv(url)\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Erro ao ler a planilha: {e}\")\n",
        "\n",
        "# Verificar se os dados foram importados corretamente\n",
        "if df is not None:\n",
        "    # Padronizar os tipos de dados\n",
        "    df = df.apply(pd.to_numeric, errors='coerce', downcast='integer')\n",
        "\n",
        "    # Verificar se as colunas esperadas estão presentes\n",
        "    expected_columns = ['Participante', 'Ausente_4', 'Ausente_12', 'Ausente_24', 'Presente_4', 'Presente_12', 'Presente_24']\n",
        "    missing_columns = [col for col in expected_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        raise ValueError(f\"As seguintes colunas estão faltando na planilha: {missing_columns}\")\n",
        "\n",
        "    # Converter o DataFrame para formato longo\n",
        "    long_df = pd.melt(df, id_vars=['Participante'],\n",
        "                      value_vars=['Ausente_4', 'Ausente_12', 'Ausente_24', 'Presente_4', 'Presente_12', 'Presente_24'],\n",
        "                      var_name='Condição', value_name='Tempo')\n",
        "\n",
        "    # Separar os fatores\n",
        "    long_df['Alvo'] = long_df['Condição'].apply(lambda x: 'Ausente' if 'Ausente' in x else 'Presente')\n",
        "    long_df['Itens'] = long_df['Condição'].apply(lambda x: int(x.split('_')[1]))\n",
        "    long_df = long_df.drop(columns=['Condição'])\n",
        "\n",
        "    # Realizar a ANOVA\n",
        "    anova = AnovaRM(long_df, depvar='Tempo', subject='Participante', within=['Alvo', 'Itens']).fit()\n",
        "\n",
        "    # Calcular médias descritivas\n",
        "    medias = long_df.groupby(['Alvo', 'Itens'])['Tempo'].mean().reset_index()\n",
        "    tabela_medias = medias.pivot(index='Itens', columns='Alvo', values='Tempo')\n",
        "    tabela_medias_texto = tabela_medias.to_string()\n",
        "\n",
        "    # Testes Post Hoc: Testes t pareados com correção de Bonferroni\n",
        "    itens_unicos = sorted(long_df['Itens'].unique())\n",
        "    post_hoc_results = []\n",
        "    for i in range(len(itens_unicos)):\n",
        "        for j in range(i + 1, len(itens_unicos)):\n",
        "            t_stat, p_value = ttest_rel(\n",
        "                long_df[long_df['Itens'] == itens_unicos[i]]['Tempo'],\n",
        "                long_df[long_df['Itens'] == itens_unicos[j]]['Tempo']\n",
        "            )\n",
        "            post_hoc_results.append({\n",
        "                'Comparação': f\"{itens_unicos[i]} vs {itens_unicos[j]}\",\n",
        "                't-Estatístico': t_stat,\n",
        "                'p-Valor (não corrigido)': p_value\n",
        "            })\n",
        "\n",
        "    post_hoc_df = pd.DataFrame(post_hoc_results)\n",
        "\n",
        "    # Verificar efeitos principais e interação\n",
        "    efeito_principal_itens = anova.anova_table.loc['Itens', 'Pr > F']\n",
        "    efeito_principal_alvo = anova.anova_table.loc['Alvo', 'Pr > F']\n",
        "    interacao = anova.anova_table.loc['Alvo:Itens', 'Pr > F']\n",
        "\n",
        "    if efeito_principal_itens < 0.05:\n",
        "        resultado_itens = (f\"Houve um efeito principal de número de itens, \"\n",
        "                          f\"F(2,14) = {anova.anova_table.loc['Itens', 'F Value']:.2f}, p < 0.001.\")\n",
        "    else:\n",
        "        resultado_itens = (f\"Não foi encontrado o efeito principal de número de itens, \"\n",
        "                          f\"F(2,14) = {anova.anova_table.loc['Itens', 'F Value']:.2f}, p = {efeito_principal_itens:.3f}.\")\n",
        "\n",
        "    if efeito_principal_alvo < 0.05:\n",
        "        resultado_alvo = (f\"Houve um efeito principal de presença do alvo, \"\n",
        "                          f\"F(1,7) = {anova.anova_table.loc['Alvo', 'F Value']:.2f}, p = {efeito_principal_alvo:.3f}, \"\n",
        "                          f\"com tempo médio de resposta mais curto quando o alvo estava presente.\")\n",
        "    else:\n",
        "        resultado_alvo = (f\"Não foi encontrado o efeito principal de presença do alvo, \"\n",
        "                          f\"F(1,7) = {anova.anova_table.loc['Alvo', 'F Value']:.2f}, p = {efeito_principal_alvo:.3f}.\")\n",
        "\n",
        "    # Realizar uma regressão linear para calcular R²\n",
        "    X = long_df[['Itens']]\n",
        "    y = long_df['Tempo']\n",
        "\n",
        "    reg = LinearRegression()\n",
        "    reg.fit(X, y)\n",
        "    r2 = reg.score(X, y)\n",
        "\n",
        "    # Preparar o sumário em texto\n",
        "    sumario_texto = \"\"\"\n",
        "Análise Detalhada do Experimento de Busca Visual\n",
        "-------------------------------------------------\n",
        "\n",
        "1. Estatísticas Descritivas:\n",
        "{tabela_medias}\n",
        "\n",
        "2. Resultados da ANOVA:\n",
        "{anova_resultados}\n",
        "\n",
        "3. Testes Post Hoc (t de Student pareado com Bonferroni):\n",
        "{post_hoc}\n",
        "\n",
        "4. Regressão Linear:\n",
        "R² = {r2:.3f}\n",
        "\n",
        "Conclusões:\n",
        "- {resultado_itens}\n",
        "- {resultado_alvo}\n",
        "- Houve uma interação significativa entre a presença do alvo e o número de itens (p = {interacao:.3f}).\n",
        "\"\"\".format(\n",
        "        tabela_medias=tabela_medias_texto,\n",
        "        anova_resultados=anova.summary().as_text(),\n",
        "        post_hoc=post_hoc_df.to_string(index=False),\n",
        "        r2=r2,\n",
        "        resultado_itens=resultado_itens,\n",
        "        resultado_alvo=resultado_alvo,\n",
        "        interacao=interacao\n",
        "    )\n",
        "\n",
        "    # Criar o arquivo de sumário\n",
        "    output_path = '/content/drive/My Drive/sumario.txt'\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write(sumario_texto)\n",
        "\n",
        "    print(f\"Arquivo de sumário salvo em: {output_path}\")"
      ]
    }
  ]
}